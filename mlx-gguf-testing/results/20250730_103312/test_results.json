{
  "test_run": {
    "timestamp": "2025-07-30T10:33:12.730404",
    "interrupted": false,
    "total_tests": 28,
    "failed_tests": 1
  },
  "results": [
    {
      "scenario": "cold_start",
      "model_type": "gguf",
      "model_id": "llama-3.3-70b-instruct@q6_k",
      "success": true,
      "errors": [],
      "metrics": {
        "idle_time": 60,
        "memory_summary": {
          "initial_mb": 18994.890625,
          "peak_mb": 19549.5625,
          "final_mb": 18633.03125,
          "avg_percent": 15.680487804878052,
          "peak_percent": 16.1
        },
        "cpu_summary": {
          "avg_percent": 8.967073170731707,
          "peak_percent": 25.7
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "simple_generation",
      "model_type": "gguf",
      "model_id": "llama-3.3-70b-instruct@q6_k",
      "success": true,
      "errors": [],
      "metrics": {
        "generation_metrics": {
          "duration": 63.4219229221344,
          "ttft": 27.599185943603516,
          "tokens_generated": 238,
          "tokens_per_second": 3.75264560004278
        },
        "memory_summary": {
          "initial_mb": 18633.4375,
          "peak_mb": 88477.75,
          "final_mb": 88305.921875,
          "avg_percent": 49.17624999999996,
          "peak_percent": 68.7
        },
        "cpu_summary": {
          "avg_percent": 10.115000000000002,
          "peak_percent": 17.2
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "context_stress",
      "model_type": "gguf",
      "model_id": "llama-3.3-70b-instruct@q6_k",
      "success": true,
      "errors": [],
      "metrics": {
        "context_size": 32768,
        "generation_metrics": {
          "duration": 85.39609122276306,
          "ttft": 19.619465351104736,
          "tokens_generated": 386,
          "tokens_per_second": 4.52011320978481
        },
        "memory_summary": {
          "initial_mb": 87073.0625,
          "peak_mb": 89153.015625,
          "final_mb": 88449.609375,
          "avg_percent": 68.68773584905658,
          "peak_percent": 69.2
        },
        "cpu_summary": {
          "avg_percent": 9.742452830188677,
          "peak_percent": 33.1
        }
      }
    },
    {
      "scenario": "memory_leak",
      "model_type": "gguf",
      "model_id": "llama-3.3-70b-instruct@q6_k",
      "success": true,
      "errors": [],
      "metrics": {
        "num_prompts": 10,
        "memory_checkpoints": [
          {
            "iteration": 0,
            "memory_mb": 87771.15625
          },
          {
            "iteration": 1,
            "memory_mb": 87776.046875
          },
          {
            "iteration": 2,
            "memory_mb": 87704.625
          },
          {
            "iteration": 3,
            "memory_mb": 87509.625
          },
          {
            "iteration": 4,
            "memory_mb": 87649.828125
          },
          {
            "iteration": 5,
            "memory_mb": 87424.4375
          },
          {
            "iteration": 6,
            "memory_mb": 87365.703125
          },
          {
            "iteration": 7,
            "memory_mb": 87585.71875
          },
          {
            "iteration": 8,
            "memory_mb": 87835.578125
          },
          {
            "iteration": 9,
            "memory_mb": 87730.703125
          }
        ],
        "memory_growth_mb": -40.453125,
        "growth_per_iteration_mb": -4.494791666666667,
        "memory_summary": {
          "initial_mb": 88002.234375,
          "peak_mb": 89886.328125,
          "final_mb": 87560.34375,
          "avg_percent": 68.84346153846148,
          "peak_percent": 69.8
        },
        "cpu_summary": {
          "avg_percent": 9.814423076923067,
          "peak_percent": 32.1
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "cold_start",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-3.3-70b-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "idle_time": 60,
        "memory_summary": {
          "initial_mb": 85687.4375,
          "peak_mb": 85687.4375,
          "final_mb": 81433.546875,
          "avg_percent": 63.50384615384624,
          "peak_percent": 66.6
        },
        "cpu_summary": {
          "avg_percent": 8.54102564102564,
          "peak_percent": 16.2
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "simple_generation",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-3.3-70b-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "generation_metrics": {
          "duration": 61.67429971694946,
          "ttft": 28.768999814987183,
          "tokens_generated": 220,
          "tokens_per_second": 3.567126031583284
        },
        "memory_summary": {
          "initial_mb": 81373.09375,
          "peak_mb": 92451.984375,
          "final_mb": 92435.671875,
          "avg_percent": 59.0906666666666,
          "peak_percent": 72.2
        },
        "cpu_summary": {
          "avg_percent": 12.244,
          "peak_percent": 27.8
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "context_stress",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-3.3-70b-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "context_size": 32768,
        "generation_metrics": {
          "duration": 76.57572817802429,
          "ttft": 17.290544033050537,
          "tokens_generated": 368,
          "tokens_per_second": 4.805700301595156
        },
        "memory_summary": {
          "initial_mb": 92397.625,
          "peak_mb": 93525.703125,
          "final_mb": 93047.40625,
          "avg_percent": 71.57802197802208,
          "peak_percent": 73.0
        },
        "cpu_summary": {
          "avg_percent": 9.68241758241758,
          "peak_percent": 19.7
        }
      }
    },
    {
      "scenario": "memory_leak",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-3.3-70b-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "num_prompts": 10,
        "memory_checkpoints": [
          {
            "iteration": 0,
            "memory_mb": 91920.578125
          },
          {
            "iteration": 1,
            "memory_mb": 91927.34375
          },
          {
            "iteration": 2,
            "memory_mb": 92178.375
          },
          {
            "iteration": 3,
            "memory_mb": 92229.125
          },
          {
            "iteration": 4,
            "memory_mb": 91966.40625
          },
          {
            "iteration": 5,
            "memory_mb": 92154.484375
          },
          {
            "iteration": 6,
            "memory_mb": 92348.125
          },
          {
            "iteration": 7,
            "memory_mb": 92758.546875
          },
          {
            "iteration": 8,
            "memory_mb": 93028.734375
          },
          {
            "iteration": 9,
            "memory_mb": 92515.484375
          }
        ],
        "memory_growth_mb": 594.90625,
        "growth_per_iteration_mb": 66.10069444444444,
        "memory_summary": {
          "initial_mb": 92964.828125,
          "peak_mb": 94365.0,
          "final_mb": 92515.484375,
          "avg_percent": 72.57763440860202,
          "peak_percent": 73.6
        },
        "cpu_summary": {
          "avg_percent": 11.27118279569892,
          "peak_percent": 31.2
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "cold_start",
      "model_type": "gguf",
      "model_id": "lmstudio-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "idle_time": 60,
        "memory_summary": {
          "initial_mb": 89642.140625,
          "peak_mb": 89642.140625,
          "final_mb": 74385.5625,
          "avg_percent": 63.78441558441559,
          "peak_percent": 70.0
        },
        "cpu_summary": {
          "avg_percent": 11.658441558441561,
          "peak_percent": 18.6
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "simple_generation",
      "model_type": "gguf",
      "model_id": "lmstudio-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "generation_metrics": {
          "duration": 41.75806474685669,
          "ttft": null,
          "tokens_generated": 0,
          "tokens_per_second": 0.0
        },
        "memory_summary": {
          "initial_mb": 73476.46875,
          "peak_mb": 122420.671875,
          "final_mb": 121705.71875,
          "avg_percent": 39.75098039215686,
          "peak_percent": 98.3
        },
        "cpu_summary": {
          "avg_percent": 13.398039215686278,
          "peak_percent": 29.1
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "context_stress",
      "model_type": "gguf",
      "model_id": "lmstudio-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "context_size": 32768,
        "generation_metrics": {
          "duration": 2.688228130340576,
          "ttft": null,
          "tokens_generated": 0,
          "tokens_per_second": 0.0
        },
        "memory_summary": {
          "initial_mb": 120597.703125,
          "peak_mb": 121621.015625,
          "final_mb": 121621.015625,
          "avg_percent": 95.9,
          "peak_percent": 97.9
        },
        "cpu_summary": {
          "avg_percent": 32.875,
          "peak_percent": 65.5
        }
      }
    },
    {
      "scenario": "memory_leak",
      "model_type": "gguf",
      "model_id": "lmstudio-community/llama-4-scout-17b-16e-instruct",
      "success": false,
      "errors": [
        "Prompt 0: 400 Bad Request: Unknown error",
        "Prompt 1: 400 Bad Request: Unknown error",
        "Prompt 2: 400 Bad Request: Unknown error",
        "Prompt 3: 400 Bad Request: Unknown error",
        "Prompt 4: 400 Bad Request: Unknown error",
        "Prompt 5: 400 Bad Request: Unknown error",
        "Prompt 6: 400 Bad Request: Unknown error",
        "Prompt 7: 400 Bad Request: Unknown error",
        "Prompt 8: 400 Bad Request: Unknown error",
        "Prompt 9: 400 Bad Request: Unknown error"
      ],
      "metrics": {
        "num_prompts": 10,
        "memory_checkpoints": [
          {
            "iteration": 0,
            "memory_mb": 120681.015625
          },
          {
            "iteration": 1,
            "memory_mb": 120634.8125
          },
          {
            "iteration": 2,
            "memory_mb": 120002.671875
          },
          {
            "iteration": 3,
            "memory_mb": 120524.984375
          },
          {
            "iteration": 4,
            "memory_mb": 120876.15625
          },
          {
            "iteration": 5,
            "memory_mb": 120143.59375
          },
          {
            "iteration": 6,
            "memory_mb": 121025.9375
          },
          {
            "iteration": 7,
            "memory_mb": 119116.09375
          },
          {
            "iteration": 8,
            "memory_mb": 120320.34375
          },
          {
            "iteration": 9,
            "memory_mb": 120308.078125
          }
        ],
        "memory_growth_mb": -372.9375,
        "growth_per_iteration_mb": -41.4375,
        "memory_summary": {
          "initial_mb": 120612.0,
          "peak_mb": 122507.75,
          "final_mb": 120059.71875,
          "avg_percent": 96.8238095238095,
          "peak_percent": 98.1
        },
        "cpu_summary": {
          "avg_percent": 17.877380952380946,
          "peak_percent": 38.2
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "moe_specific",
      "model_type": "gguf",
      "model_id": "lmstudio-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "expert_results": {
          "math": {
            "duration": 1.7185800075531006,
            "ttft": null,
            "tokens_per_second": 0.0,
            "response_length": 0
          },
          "creative": {
            "duration": 1.6615710258483887,
            "ttft": null,
            "tokens_per_second": 0.0,
            "response_length": 0
          },
          "code": {
            "duration": 1.6939640045166016,
            "ttft": null,
            "tokens_per_second": 0.0,
            "response_length": 0
          },
          "factual": {
            "duration": 1.6650919914245605,
            "ttft": null,
            "tokens_per_second": 0.0,
            "response_length": 0
          }
        },
        "memory_summary": {
          "initial_mb": 118897.265625,
          "peak_mb": 122314.734375,
          "final_mb": 122189.453125,
          "avg_percent": 97.01578947368424,
          "peak_percent": 98.0
        },
        "cpu_summary": {
          "avg_percent": 19.336842105263155,
          "peak_percent": 38.9
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "cold_start",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "idle_time": 60,
        "memory_summary": {
          "initial_mb": 114705.421875,
          "peak_mb": 114705.421875,
          "final_mb": 96810.859375,
          "avg_percent": 83.7820512820513,
          "peak_percent": 92.2
        },
        "cpu_summary": {
          "avg_percent": 13.553846153846154,
          "peak_percent": 18.4
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "simple_generation",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "generation_metrics": {
          "duration": 30.01146101951599,
          "ttft": 23.980604887008667,
          "tokens_generated": 255,
          "tokens_per_second": 8.496753951238077
        },
        "memory_summary": {
          "initial_mb": 96762.546875,
          "peak_mb": 96762.546875,
          "final_mb": 67363.53125,
          "avg_percent": 43.64054054054053,
          "peak_percent": 78.4
        },
        "cpu_summary": {
          "avg_percent": 19.856756756756752,
          "peak_percent": 23.0
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "context_stress",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "context_size": 32768,
        "generation_metrics": {
          "duration": 17.86958885192871,
          "ttft": 6.318479061126709,
          "tokens_generated": 456,
          "tokens_per_second": 25.518214424434433
        },
        "memory_summary": {
          "initial_mb": 67449.765625,
          "peak_mb": 68270.203125,
          "final_mb": 68152.171875,
          "avg_percent": 56.25454545454545,
          "peak_percent": 56.5
        },
        "cpu_summary": {
          "avg_percent": 17.577272727272728,
          "peak_percent": 25.6
        }
      }
    },
    {
      "scenario": "memory_leak",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "num_prompts": 10,
        "memory_checkpoints": [
          {
            "iteration": 0,
            "memory_mb": 66424.484375
          },
          {
            "iteration": 1,
            "memory_mb": 67741.53125
          },
          {
            "iteration": 2,
            "memory_mb": 66352.078125
          },
          {
            "iteration": 3,
            "memory_mb": 64313.453125
          },
          {
            "iteration": 4,
            "memory_mb": 66938.46875
          },
          {
            "iteration": 5,
            "memory_mb": 67133.640625
          },
          {
            "iteration": 6,
            "memory_mb": 67112.65625
          },
          {
            "iteration": 7,
            "memory_mb": 67127.609375
          },
          {
            "iteration": 8,
            "memory_mb": 67071.546875
          },
          {
            "iteration": 9,
            "memory_mb": 67320.796875
          }
        ],
        "memory_growth_mb": 896.3125,
        "growth_per_iteration_mb": 99.59027777777777,
        "memory_summary": {
          "initial_mb": 68195.40625,
          "peak_mb": 68378.265625,
          "final_mb": 67086.828125,
          "avg_percent": 55.67721518987341,
          "peak_percent": 56.6
        },
        "cpu_summary": {
          "avg_percent": 17.667088607594938,
          "peak_percent": 32.8
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "moe_specific",
      "model_type": "mlx",
      "model_id": "mlx-community/llama-4-scout-17b-16e-instruct",
      "success": true,
      "errors": [],
      "metrics": {
        "expert_results": {
          "math": {
            "duration": 10.594348907470703,
            "ttft": 3.5625009536743164,
            "tokens_per_second": 27.46747370145594,
            "response_length": 844
          },
          "creative": {
            "duration": 9.223774194717407,
            "ttft": 3.4317591190338135,
            "tokens_per_second": 26.670210567479835,
            "response_length": 1180
          },
          "code": {
            "duration": 10.54044508934021,
            "ttft": 3.429734945297241,
            "tokens_per_second": 28.272050892933745,
            "response_length": 1462
          },
          "factual": {
            "duration": 10.60831594467163,
            "ttft": 3.5062499046325684,
            "tokens_per_second": 27.619841031145825,
            "response_length": 1354
          }
        },
        "memory_summary": {
          "initial_mb": 65600.125,
          "peak_mb": 68081.5,
          "final_mb": 67925.734375,
          "avg_percent": 55.932203389830455,
          "peak_percent": 56.3
        },
        "cpu_summary": {
          "avg_percent": 18.55254237288136,
          "peak_percent": 29.0
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "cold_start",
      "model_type": "gguf",
      "model_id": "maziyarpanahi/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "idle_time": 60,
        "memory_summary": {
          "initial_mb": 64649.203125,
          "peak_mb": 65706.421875,
          "final_mb": 65207.84375,
          "avg_percent": 53.77600000000009,
          "peak_percent": 54.3
        },
        "cpu_summary": {
          "avg_percent": 14.842666666666668,
          "peak_percent": 40.1
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "simple_generation",
      "model_type": "gguf",
      "model_id": "maziyarpanahi/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "generation_metrics": {
          "duration": 59.14102602005005,
          "ttft": 45.76586103439331,
          "tokens_generated": 234,
          "tokens_per_second": 3.95664424084677
        },
        "memory_summary": {
          "initial_mb": 65205.3125,
          "peak_mb": 86299.484375,
          "final_mb": 86267.21875,
          "avg_percent": 35.90000000000002,
          "peak_percent": 69.9
        },
        "cpu_summary": {
          "avg_percent": 13.812328767123292,
          "peak_percent": 22.6
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "context_stress",
      "model_type": "gguf",
      "model_id": "maziyarpanahi/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "context_size": 32768,
        "generation_metrics": {
          "duration": 33.556177854537964,
          "ttft": 15.26620078086853,
          "tokens_generated": 252,
          "tokens_per_second": 7.509794503187758
        },
        "memory_summary": {
          "initial_mb": 86287.609375,
          "peak_mb": 87683.96875,
          "final_mb": 86456.3125,
          "avg_percent": 70.58000000000003,
          "peak_percent": 71.0
        },
        "cpu_summary": {
          "avg_percent": 10.577499999999999,
          "peak_percent": 17.3
        }
      }
    },
    {
      "scenario": "memory_leak",
      "model_type": "gguf",
      "model_id": "maziyarpanahi/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "num_prompts": 10,
        "memory_checkpoints": [
          {
            "iteration": 0,
            "memory_mb": 86420.90625
          },
          {
            "iteration": 1,
            "memory_mb": 86528.75
          },
          {
            "iteration": 2,
            "memory_mb": 86538.265625
          },
          {
            "iteration": 3,
            "memory_mb": 86574.03125
          },
          {
            "iteration": 4,
            "memory_mb": 86624.515625
          },
          {
            "iteration": 5,
            "memory_mb": 86593.09375
          },
          {
            "iteration": 6,
            "memory_mb": 86743.71875
          },
          {
            "iteration": 7,
            "memory_mb": 86755.265625
          },
          {
            "iteration": 8,
            "memory_mb": 86750.1875
          },
          {
            "iteration": 9,
            "memory_mb": 86749.546875
          }
        ],
        "memory_growth_mb": 328.640625,
        "growth_per_iteration_mb": 36.515625,
        "memory_summary": {
          "initial_mb": 86413.109375,
          "peak_mb": 87036.734375,
          "final_mb": 86749.546875,
          "avg_percent": 70.20624999999995,
          "peak_percent": 70.4
        },
        "cpu_summary": {
          "avg_percent": 14.19117647058825,
          "peak_percent": 32.7
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "moe_specific",
      "model_type": "gguf",
      "model_id": "maziyarpanahi/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "expert_results": {
          "math": {
            "duration": 26.003392934799194,
            "ttft": 2.8212549686431885,
            "tokens_per_second": 10.729369075011231,
            "response_length": 846
          },
          "creative": {
            "duration": 25.680770874023438,
            "ttft": 2.3487000465393066,
            "tokens_per_second": 11.642952677189449,
            "response_length": 1225
          },
          "code": {
            "duration": 25.387933254241943,
            "ttft": 2.3276360034942627,
            "tokens_per_second": 11.77724854582409,
            "response_length": 1075
          },
          "factual": {
            "duration": 25.6336932182312,
            "ttft": 2.593461275100708,
            "tokens_per_second": 11.66433558576511,
            "response_length": 1328
          }
        },
        "memory_summary": {
          "initial_mb": 86796.90625,
          "peak_mb": 87119.828125,
          "final_mb": 87096.046875,
          "avg_percent": 70.31240875912398,
          "peak_percent": 70.5
        },
        "cpu_summary": {
          "avg_percent": 11.347445255474454,
          "peak_percent": 18.6
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "cold_start",
      "model_type": "mlx",
      "model_id": "mlx-community/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "idle_time": 60,
        "memory_summary": {
          "initial_mb": 87056.984375,
          "peak_mb": 87111.8125,
          "final_mb": 86968.34375,
          "avg_percent": 70.33947368421063,
          "peak_percent": 70.4
        },
        "cpu_summary": {
          "avg_percent": 11.58026315789474,
          "peak_percent": 15.5
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "simple_generation",
      "model_type": "mlx",
      "model_id": "mlx-community/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "generation_metrics": {
          "duration": 44.44015407562256,
          "ttft": 32.22397804260254,
          "tokens_generated": 240,
          "tokens_per_second": 5.400521330137577
        },
        "memory_summary": {
          "initial_mb": 86964.8125,
          "peak_mb": 89595.609375,
          "final_mb": 89595.609375,
          "avg_percent": 52.99230769230768,
          "peak_percent": 72.3
        },
        "cpu_summary": {
          "avg_percent": 18.094230769230766,
          "peak_percent": 29.6
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "context_stress",
      "model_type": "mlx",
      "model_id": "mlx-community/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "context_size": 32768,
        "generation_metrics": {
          "duration": 36.63157415390015,
          "ttft": 12.7277991771698,
          "tokens_generated": 424,
          "tokens_per_second": 11.574714158300972
        },
        "memory_summary": {
          "initial_mb": 89584.578125,
          "peak_mb": 90372.859375,
          "final_mb": 89980.140625,
          "avg_percent": 70.71428571428575,
          "peak_percent": 72.8
        },
        "cpu_summary": {
          "avg_percent": 13.876190476190473,
          "peak_percent": 17.8
        }
      }
    },
    {
      "scenario": "memory_leak",
      "model_type": "mlx",
      "model_id": "mlx-community/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "num_prompts": 10,
        "memory_checkpoints": [
          {
            "iteration": 0,
            "memory_mb": 89029.1875
          },
          {
            "iteration": 1,
            "memory_mb": 88015.515625
          },
          {
            "iteration": 2,
            "memory_mb": 87907.640625
          },
          {
            "iteration": 3,
            "memory_mb": 87409.828125
          },
          {
            "iteration": 4,
            "memory_mb": 86609.421875
          },
          {
            "iteration": 5,
            "memory_mb": 86329.109375
          },
          {
            "iteration": 6,
            "memory_mb": 87929.015625
          },
          {
            "iteration": 7,
            "memory_mb": 87700.890625
          },
          {
            "iteration": 8,
            "memory_mb": 87641.015625
          },
          {
            "iteration": 9,
            "memory_mb": 86591.953125
          }
        ],
        "memory_growth_mb": -2437.234375,
        "growth_per_iteration_mb": -270.80381944444446,
        "memory_summary": {
          "initial_mb": 90711.78125,
          "peak_mb": 90711.78125,
          "final_mb": 86591.953125,
          "avg_percent": 70.94202127659572,
          "peak_percent": 73.0
        },
        "cpu_summary": {
          "avg_percent": 9.830851063829787,
          "peak_percent": 17.3
        },
        "context_size": 32768
      }
    },
    {
      "scenario": "moe_specific",
      "model_type": "mlx",
      "model_id": "mlx-community/mixtral-8x22b-instruct-v0.1",
      "success": true,
      "errors": [],
      "metrics": {
        "expert_results": {
          "math": {
            "duration": 18.140803813934326,
            "ttft": 2.664738655090332,
            "tokens_per_second": 16.48218034144286,
            "response_length": 799
          },
          "creative": {
            "duration": 17.736743927001953,
            "ttft": 2.652407169342041,
            "tokens_per_second": 16.8576600773274,
            "response_length": 1212
          },
          "code": {
            "duration": 17.664507150650024,
            "ttft": 2.5672121047973633,
            "tokens_per_second": 16.92659735423172,
            "response_length": 1091
          },
          "factual": {
            "duration": 17.67207908630371,
            "ttft": 2.8063950538635254,
            "tokens_per_second": 16.862758396716163,
            "response_length": 1269
          }
        },
        "memory_summary": {
          "initial_mb": 85659.0,
          "peak_mb": 88364.109375,
          "final_mb": 88249.0625,
          "avg_percent": 70.81914893617014,
          "peak_percent": 71.1
        },
        "cpu_summary": {
          "avg_percent": 10.209574468085103,
          "peak_percent": 16.3
        },
        "context_size": 32768
      }
    }
  ]
}